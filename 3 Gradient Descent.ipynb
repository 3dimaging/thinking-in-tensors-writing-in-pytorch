{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking in tensors in PyTorch\n",
    "\n",
    "Deep learning for neuroscientists - hands-on training  by [Piotr MigdaÅ‚](https://p.migdal.pl) (2019). Version 0.2.\n",
    "\n",
    "\n",
    "\n",
    "## Notebook 3: Gradient descent\n",
    "\n",
    "\n",
    "> X: I want to learn Deep Learning.  \n",
    "> Me: Do you know what is gradient?  \n",
    "> X: Yes  \n",
    "> Me: Then, it an easy way downhill!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = x^2$$\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x} = 2 x$$\n",
    "\n",
    "For $y^2$ we can calculate it:\n",
    "\n",
    "$$\\lim_{x \\to 0} \\frac{y(x + h) - y(x)} {h}$$\n",
    "\n",
    "Limit is a mathematic tool for \n",
    "\n",
    "$$\\frac{x^2 + 2 x h + h^2 - x^2}{h} = 2 x + h $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-4, 4, num=100)\n",
    "Y = X**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT: it seem to look better when on a different plot\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(7, 4))\n",
    "\n",
    "ax0.plot(X, Y)\n",
    "ax0.set(title='', xlabel='', ylabel='y')\n",
    "\n",
    "ax1.plot(X, 2 * X)\n",
    "ax1.set(title='', xlabel='x', ylabel='dy/dx')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# or maybe Bokeh with mouseover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical derivative in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can go it automatically\n",
    "plt.plot((X[1:] + X[:-1]) / 2, np.diff(Y) / np.diff(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic derivative in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(4., requires_grad=True)\n",
    "y = x.pow(2)\n",
    "y.backward()\n",
    "\n",
    "# y\n",
    "y\n",
    "\n",
    "# dy / dx\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.75\n",
    "x0 = 4.\n",
    "\n",
    "xs = [x0]\n",
    "x = torch.tensor(x0, requires_grad=True)\n",
    "\n",
    "for i in range(10):\n",
    "    y = x.pow(2)\n",
    "    y.backward()\n",
    "    x.data.add_(- lr * x.grad.data)\n",
    "    x.grad.data.zero_()\n",
    "    xs.append(x.item())\n",
    "\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_X = np.array(xs)\n",
    "points_Y = points_X**2\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 4))\n",
    "ax.plot(X, Y)\n",
    "ax.plot(points_X, points_Y, '-')\n",
    "ax.plot(points_X, points_Y, 'r.')\n",
    "ax.set(title='Gradient descent', xlabel='x', ylabel='y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try other learning rates, e.g.:\n",
    "\n",
    "* 0.1\n",
    "* 0.5\n",
    "* 0.75\n",
    "* 1.\n",
    "* 1.5\n",
    "* -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly more complex function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x):\n",
    "    return x - 4 * x**2 + 0.25 * x**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-4, 4, num=100)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(7, 4))\n",
    "\n",
    "ax0.plot(X, poly(X))\n",
    "ax0.set(title='', xlabel='', ylabel='y')\n",
    "\n",
    "ax1.plot(X, 2 * X)\n",
    "ax1.set(title='', xlabel='x', ylabel='dy/dx')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "x0 = 4.\n",
    "\n",
    "xs = [x0]\n",
    "x = torch.tensor(x0, requires_grad=True)\n",
    "\n",
    "for i in range(10):\n",
    "    y = poly(x)\n",
    "    y.backward()\n",
    "    x.data.add_(- lr * x.grad.data)\n",
    "    x.grad.data.zero_()\n",
    "    xs.append(x.item())\n",
    "\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_X = np.array(xs)\n",
    "points_Y = poly(points_X)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 4))\n",
    "ax.plot(X, poly(X))\n",
    "ax.plot(points_X, points_Y, '-')\n",
    "ax.plot(points_X, points_Y, 'r.')\n",
    "ax.set(title='Gradient descent', xlabel='x', ylabel='y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_ = np.linspace(-4, 4, num=100)\n",
    "X1_ = np.linspace(-4, 4, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1 = np.meshgrid(X0_, X1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X0**2 + np.sin(X1), cmap='coolwarm')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, let's draw a [contour plot](https://en.wikipedia.org/wiki/Contour_line), well known from topographic maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = plt.contour(X0, X1, X0**2 + np.sin(X1), cmap='coolwarm')\n",
    "plt.clabel(cs, inline=1, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.25\n",
    "v = [-2., -2.]\n",
    "\n",
    "xs = [v[0]]\n",
    "ys = [v[1]]\n",
    "v = torch.tensor(v, requires_grad=True)\n",
    "\n",
    "for i in range(10):\n",
    "    y = v[0].pow(2) + v[1].sin()\n",
    "    y.backward()\n",
    "    v.data.add_(- lr * v.grad.data)\n",
    "    v.grad.data.zero_()\n",
    "    \n",
    "    xs.append(v[0].item())\n",
    "    ys.append(v[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = plt.contour(X0, X1, X0**2 + np.sin(X1), cmap='coolwarm')\n",
    "plt.clabel(cs, inline=1, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dos (notes to myself)\n",
    "\n",
    "Refer to:\n",
    "\n",
    "* more advanced methods (with Hessian)\n",
    "* JAX\n",
    "\n",
    "Links for myself:\n",
    "\n",
    "* https://github.com/d3/d3-contour\n",
    "\n",
    "\n",
    "Notes in general:\n",
    "\n",
    "* memic content\n",
    "* Small exercises\n",
    "* Links and references\n",
    "* Show this Kalman filters as a reference "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
