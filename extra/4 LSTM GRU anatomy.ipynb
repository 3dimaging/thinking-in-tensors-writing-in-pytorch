{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking in tensors in PyTorch\n",
    "\n",
    "Hands-on training  by [Piotr Migda≈Ç](https://p.migdal.pl) (2019). \n",
    "\n",
    "Version for [AI & NLP Workshop Day](https://nlpday.pl/), 31 May 2019, Warsaw, Poland: **Understanding LSTM and GRU networks in PyTorch**.\n",
    "\n",
    "\n",
    "\n",
    "## NLP & AI: 4. LSTM GRU anatomy\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stared/thinking-in-tensors-writing-in-pytorch/blob/master/extra/4%20LSTM%20GRU%20anatomy.ipynb)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "More in https://pytorch.org/docs/stable/nn.html#lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = 8 (length)\n",
    "# B = 1 (batch size)\n",
    "# C = 5 (channels)\n",
    "x = torch.randn(8, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9475,  0.0295, -0.9345,  0.0686,  0.1173]],\n",
       "\n",
       "        [[ 0.4105,  1.0467, -0.5570, -0.9523,  0.3352]],\n",
       "\n",
       "        [[ 0.3378,  0.6555, -0.2683, -0.3765,  0.2690]],\n",
       "\n",
       "        [[ 0.8649,  0.7311,  0.0932, -1.3769, -1.3036]],\n",
       "\n",
       "        [[-0.7326, -0.7776,  1.1224,  0.2065, -0.5358]],\n",
       "\n",
       "        [[ 1.1138, -2.7978, -1.3544, -0.3246, -0.5382]],\n",
       "\n",
       "        [[-0.3468,  0.2607, -0.0527, -0.2501, -1.4180]],\n",
       "\n",
       "        [[ 0.9567, -0.1102,  1.1552,  0.6020, -0.8374]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden, cell) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0337,  0.2362,  0.4257]],\n",
       "\n",
       "        [[-0.1345, -0.0277,  0.2995]],\n",
       "\n",
       "        [[-0.2241, -0.0752,  0.3286]],\n",
       "\n",
       "        [[-0.3758, -0.0412,  0.3113]],\n",
       "\n",
       "        [[-0.4010,  0.0884,  0.3689]],\n",
       "\n",
       "        [[-0.3639,  0.1844,  0.3982]],\n",
       "\n",
       "        [[-0.4993,  0.1345,  0.4895]],\n",
       "\n",
       "        [[-0.7292,  0.1251,  0.2716]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7292,  0.1251,  0.2716]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3856,  0.3687,  0.5565]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1] == hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, (hidden1, cell1) = lstm(x[:4])\n",
    "output2, (hidden2, cell2) = lstm(x[4:], (hidden1, cell1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0337,  0.2362,  0.4257]],\n",
       "\n",
       "        [[-0.1345, -0.0277,  0.2995]],\n",
       "\n",
       "        [[-0.2241, -0.0752,  0.3286]],\n",
       "\n",
       "        [[-0.3758, -0.0412,  0.3113]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4010,  0.0884,  0.3689]],\n",
       "\n",
       "        [[-0.3639,  0.1844,  0.3982]],\n",
       "\n",
       "        [[-0.4993,  0.1345,  0.4895]],\n",
       "\n",
       "        [[-0.7292,  0.1251,  0.2716]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0337,  0.2362,  0.4257]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.1345, -0.0277,  0.2995]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.2241, -0.0752,  0.3286]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.3758, -0.0412,  0.3113]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.4010,  0.0884,  0.3689]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.3639,  0.1844,  0.3982]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.4993,  0.1345,  0.4895]]], grad_fn=<StackBackward>)\n",
      "tensor([[[-0.7292,  0.1251,  0.2716]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.tensor([[[ 0., 0., 0.]]])\n",
    "cell = torch.tensor([[[ 0., 0., 0.]]])\n",
    "for i, token in enumerate(x):\n",
    "    output, (hidden, cell) = lstm(x[i:i+1], (hidden, cell))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "More in https://pytorch.org/docs/stable/nn.html#gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that instead of (hidden, cell) there is only hidden\n",
    "output, hidden = gru(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1094, -0.2984,  0.1891]],\n",
       "\n",
       "        [[-0.2014,  0.1291,  0.2487]],\n",
       "\n",
       "        [[-0.4000,  0.4376,  0.1978]],\n",
       "\n",
       "        [[-0.3034,  0.5555, -0.0470]],\n",
       "\n",
       "        [[-0.3015, -0.1367, -0.2690]],\n",
       "\n",
       "        [[-0.1638,  0.3410, -0.5762]],\n",
       "\n",
       "        [[-0.1888, -0.1596, -0.4027]],\n",
       "\n",
       "        [[-0.7913, -0.0711, -0.6111]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7913, -0.0711, -0.6111]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM\n",
    "\n",
    "See also: [Understanding Bidirectional RNN in PyTorch](https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66) by Cechine Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = nn.LSTM(5, 3, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden, cell) = bilstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2669, -0.0221,  0.2699, -0.0720,  0.1682, -0.1084]],\n",
       "\n",
       "        [[-0.1504,  0.0893,  0.1900, -0.3417, -0.0821, -0.0734]],\n",
       "\n",
       "        [[-0.1624,  0.1026,  0.2249, -0.2898, -0.0608, -0.0698]],\n",
       "\n",
       "        [[-0.1411,  0.0305,  0.0147, -0.2639, -0.1124,  0.0594]],\n",
       "\n",
       "        [[-0.2125, -0.0408,  0.1421, -0.0245,  0.0406,  0.0628]],\n",
       "\n",
       "        [[-0.0033,  0.3355,  0.3107, -0.0323, -0.0737, -0.1409]],\n",
       "\n",
       "        [[-0.2040, -0.0687,  0.1029, -0.1220, -0.1299, -0.0108]],\n",
       "\n",
       "        [[-0.0140, -0.3609,  0.1000, -0.1549, -0.1223, -0.0972]]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0140, -0.3609,  0.1000]],\n",
       "\n",
       "        [[-0.0720,  0.1682, -0.1084]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-layered LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilstm = nn.LSTM(5, 3, num_layers=2, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden, cell) = multilstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1479,  0.1397,  0.0706, -0.1380,  0.3392, -0.2939]],\n",
       "\n",
       "        [[ 0.2466,  0.1548,  0.1389, -0.1487,  0.2985, -0.2765]],\n",
       "\n",
       "        [[ 0.2980,  0.1424,  0.1756, -0.1356,  0.2838, -0.2714]],\n",
       "\n",
       "        [[ 0.3256,  0.1475,  0.1853, -0.1240,  0.2768, -0.2555]],\n",
       "\n",
       "        [[ 0.3314,  0.1064,  0.1445, -0.1045,  0.2236, -0.2474]],\n",
       "\n",
       "        [[ 0.3407,  0.0577,  0.1794, -0.1044,  0.2029, -0.2230]],\n",
       "\n",
       "        [[ 0.4067,  0.1002,  0.1415, -0.0825,  0.2006, -0.1969]],\n",
       "\n",
       "        [[ 0.3843,  0.0553,  0.1478, -0.0613,  0.0966, -0.0805]]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3624,  0.5248, -0.1750]],\n",
       "\n",
       "        [[ 0.0545,  0.0592, -0.2942]],\n",
       "\n",
       "        [[ 0.3843,  0.0553,  0.1478]],\n",
       "\n",
       "        [[-0.1380,  0.3392, -0.2939]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
