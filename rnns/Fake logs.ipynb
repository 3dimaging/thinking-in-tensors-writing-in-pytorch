{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking in tensors in PyTorch\n",
    "\n",
    "Hands-on training  by [Piotr Migdał](https://p.migdal.pl) (2020). A short training for Sumo Logic Warsaw, 17 Jan 2020.\n",
    "\n",
    "* Open in Colab: https://colab.research.google.com/github/stared/thinking-in-tensors-writing-in-pytorch/\n",
    "* If you want to run it locally, the easiest way is to use Python 3.7+ from [Anaconda Distribution](https://www.anaconda.com/distribution/), install [PyTorch](https://pytorch.org/) and run `jupyter notebook`.\n",
    "\n",
    "\n",
    "## Generating f̶a̶k̶e artificial logs\n",
    "\n",
    "\n",
    "### Background reading\n",
    "\n",
    "We use recurrent networks. For wonderful introductions:\n",
    "\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah\n",
    "* [Exploring LSTMs](http://blog.echen.me/2017/05/30/exploring-lstms/) by Edwin Chen\t\n",
    "\n",
    "\n",
    "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
    "\n",
    "See also:\n",
    "\n",
    "* [Simple diagrams of convoluted neural networks](https://medium.com/inbrowserai/simple-diagrams-of-convoluted-neural-networks-39c097d2925b) by Piotr Migdał\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy\n",
    "* [Memorization in RNNs](https://distill.pub/2019/memorization-in-rnns/)\n",
    "* [Unsupervised sentiment neuron by OpenAI](https://openai.com/blog/unsupervised-sentiment-neuron/)\n",
    "* [GPT-2: Better Language Models and Their Implications](https://openai.com/blog/better-language-models/) by OpenAI\n",
    "\n",
    "Play online:\n",
    "\n",
    "\n",
    "* [RecurrentJS](http://cs.stanford.edu/people/karpathy/recurrentjs) - an in-browser demo by Andrej Karpathy\n",
    "* [transformer.huggingface.co](https://transformer.huggingface.co/) - autocompletion with state-of-the-art models\n",
    "\n",
    "Other\n",
    "\n",
    "* [Training a Keras model to generate colors](https://heartbeat.fritz.ai/how-to-train-a-keras-model-to-generate-colors-3bc79e54971b)\n",
    "* [Generating Magic cards using deep, recurrent neural networks](https://www.mtgsalvation.com/forums/magic-fundamentals/custom-card-creation/612057-generating-magic-cards-using-deep-recurrent-neural)\n",
    "\n",
    "\n",
    "### Various practical links\n",
    "\n",
    "* [What is the best way to remove accents in a Python unicode string?](https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string)\n",
    "* My [livelossplot Python package](https://github.com/stared/livelossplot) - live training loss plot in Jupyter Notebook for Keras, PyTorch and others (now over 100k downloads!)\n",
    "\n",
    "### ...and where is mine command log file\n",
    "\n",
    "* Windows PowerShell: `~\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadline\\ConsoleHost_history.txt`\n",
    "* Linux & macOS Bash: `~/.bash_history`\n",
    "* Zsh: `~/.zsh_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode\n",
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU\n",
    "\n",
    "* [GPU benchmarks for deep learning tasks](https://www.reddit.com/r/MachineLearning/comments/ecazk2/d_gpu_benchmarks_for_deep_learning_tasks/) - my overview\n",
    "* [ai-benchmark.com/alpha](http://ai-benchmark.com/alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_properties('cuda:0')\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\\n\")\n",
    "    print(f\"{gpu.name}\")\n",
    "    print(f\"({gpu.total_memory//2**20}MB memory, {gpu.multi_processor_count} multiprocessors)\\n\")\n",
    "    print(f\"CUDA version:  {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {gpu.major}.{gpu.minor}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data\n",
    "\n",
    "We use a fragment of: https://archive.ics.uci.edu/ml/datasets/UNIX+User+Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O commands.txt https://www.dropbox.com/s/qed5mrji0yraoev/sanitized_all_1.981115184025?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"commands.txt\") as f:\n",
    "    data = f.read()\n",
    "    lines = data.replace(\"\\n\", \" \").replace(\"**SOF**\", \"\").split(\"**EOF**\")\n",
    "    lines = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "for line in lines:\n",
    "    word_counter.update(line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_counter = Counter([len(line) for line in lines])\n",
    "pd.Series(len_counter).sort_index().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = Counter()\n",
    "for line in lines:\n",
    "    letters.update(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = {c: i for i, (c, v) in enumerate(letters.items())}\n",
    "id2char = {i: c for i, (c, v) in enumerate(letters.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "BEGIN_ID = len(char2id)\n",
    "AFTER_ID = len(char2id) + 1\n",
    "\n",
    "X = np.zeros((len(lines), max_len), dtype=np.int64)\n",
    "X[:,:] = AFTER_ID\n",
    "X[:,0] = BEGIN_ID\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    for j, c in enumerate(line):\n",
    "        if j + 1 >= max_len:\n",
    "            break\n",
    "        X[i, j + 1] = char2id[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [c for i, c in id2char.items()] + [\">\", \"<\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(name, end=True):\n",
    "    code = [char2id[c] for c in name.lower()]\n",
    "    if end:\n",
    "        return torch.tensor([BEGIN_ID] + code + [AFTER_ID]).unsqueeze(0)\n",
    "    else:\n",
    "        return torch.tensor([BEGIN_ID] + code).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(\"sudo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, = train_test_split(X, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(torch.from_numpy(X_train).long()),\n",
    "                         batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(TensorDataset(torch.from_numpy(X_test).long()),\n",
    "                         batch_size=128, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": trainloader,\n",
    "    \"validation\": testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gener(model, criterion, optimizer, num_epochs=10,\n",
    "                      device=device,\n",
    "                      trainloader=trainloader,\n",
    "                      testloader=testloader):\n",
    "    \n",
    "    # creating plots\n",
    "    liveloss = PlotLosses()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # main train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        logs = {}\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # accumulating error measures\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for (inputs_full,) in dataloaders[phase]:\n",
    "                \n",
    "                # here are changes!\n",
    "                inputs = inputs_full[:, :-1].to(device)\n",
    "                labels = inputs_full[:, 1:].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # training the model with a variant\n",
    "                # of the gradient descent\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.detach() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            prefix = ''\n",
    "            if phase == 'validation':\n",
    "                prefix = 'val_'\n",
    "\n",
    "            logs[prefix + 'log loss'] = epoch_loss.item()\n",
    "            logs[prefix + 'accuracy'] = epoch_acc.item()\n",
    "        \n",
    "        liveloss.update(logs)\n",
    "        liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dictionary_len=len(chars)):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(dictionary_len, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        # note: input size is the numer of channels/embedding dim, NOT length\n",
    "        self.fc = nn.Linear(hidden_size, dictionary_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.permute(1, 0, 2)  # BLC -> LBC\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        res = self.fc(output)\n",
    "        return res.permute(1, 2, 0) #  LBC -> BCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example = torch.from_numpy(X_train[:3]).long().to(device)\n",
    "X_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sample size, sequence length)\n",
    "X_example.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model; it has random weights\n",
    "model = GenerativeLSTM(embedding_size=5, hidden_size=16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sample size, alphabet size, sequence length)\n",
    "model(X_example).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's train a model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model_gener(model, criterion, optimizer, num_epochs=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(encode(\"sourc\", end=False).to(device))\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_letter_prob = pred[0,:,-1].softmax(dim=0).cpu().detach().numpy()\n",
    "next_letter_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * pd.Series(next_letter_prob, index=chars).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 * pd.Series(next_letter_prob, index=chars).sort_values(ascending=False)).head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_char_id = np.random.choice(len(next_letter_prob), 1, p=next_letter_prob)[0]\n",
    "next_char_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars[next_char_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start=\"\", next_chars=20, temperature=1., model=model, device=device):\n",
    "    word = start\n",
    "\n",
    "    for i in range(next_chars):\n",
    "        pred = model(encode(word, end=False).to(device))\n",
    "        next_letter_prob = pred[0,:,-1].softmax(dim=0).cpu().detach().numpy()\n",
    "  \n",
    "        next_letter_prob = next_letter_prob**(1/temperature)\n",
    "        next_letter_prob = next_letter_prob / next_letter_prob.sum()\n",
    "\n",
    "        next_char_id = np.random.choice(len(next_letter_prob), 1, p=next_letter_prob)[0]\n",
    "\n",
    "        word += chars[next_char_id]\n",
    "\n",
    "        if chars[next_char_id] == '<':\n",
    "            word = word[:-1]\n",
    "            break\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate(\"l\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate(\"exi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate(\"sudo rm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(generate(\"l\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37-pytorch",
   "language": "python",
   "name": "p37-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
